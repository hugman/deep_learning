{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DNN Sample Code (MNIST)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cPickle as pkl\n",
    "import os, sys\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we have sampled mnist data at ./data folder\n",
    "- image file : np_image_file.10k.pkl  <-- pickled objects\n",
    "- label file : np_label_file.10k.pkl  <-- pickled objects\n",
    "\n",
    "a image of minst is 28x28 pixel image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# loading and checking\n",
    "\n",
    "with open('./data/np_image_file.10k.pkl') as image_f:\n",
    "    images = pkl.load(image_f)\n",
    "\n",
    "with open('./data/np_label_file.10k.pkl') as label_f:\n",
    "    labels = pkl.load(label_f)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 784)\n",
      "10000\n",
      "784\n",
      "(10000,)\n",
      "7\n"
     ]
    }
   ],
   "source": [
    "type(images)\n",
    "print images.shape\n",
    "print len(images)\n",
    "print len(images[0])\n",
    "\n",
    "type(labels)\n",
    "print labels.shape\n",
    "print labels[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sample image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPwAAAD7CAYAAABOrvnfAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n3q8AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fcf60d7c9d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# from https://github.com/mnielsen/neural-networks-and-deep-learning/blob/master/fig/mnist.py\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "def show_image(an_image, shape=[28,28]):\n",
    "    sample_image = 1.0 - np.reshape(an_image, shape)\n",
    "\n",
    "    # gray map : 1.0 --> black, 0.0 --> white\n",
    "    plt.matshow(sample_image, cmap=plt.cm.gray)\n",
    "    plt.show()    \n",
    "    \n",
    "an_image = images[100]\n",
    "show_image(an_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## data reader (batch-wise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "def batch_reader(start_index):\n",
    "    # read data[start_index:start_index+batch_size]\n",
    "    # return [batch_size, 784], [batch_size]\n",
    "    try:\n",
    "        batch_images = images[start_index:start_index+batch_size]\n",
    "        batch_labels = labels[start_index:start_index+batch_size]\n",
    "        return np.array(batch_images), batch_labels\n",
    "    except:\n",
    "        return None, None\n",
    "# check"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor 'hidden_1/Relu:0' shape=(100, 144) dtype=float32>,\n",
       " <tf.Tensor 'hidden_2/Relu:0' shape=(100, 36) dtype=float32>,\n",
       " <tf.Tensor 'hidden_3/add:0' shape=(100, 10) dtype=float32>)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def variable_init_2D(num_input, num_output):\n",
    "    \"\"\"\n",
    "    Initialize weight matrix using truncated normal method\n",
    "      check detail from Lecun (98) paper.\n",
    "       - http://yann.lecun.com/exdb/publis/pdf/lecun-98b.pdf\n",
    "    \"\"\"\n",
    "    init_tensor = tf.truncated_normal([num_input, num_output], stddev=1.0 / math.sqrt(float(num_input)))\n",
    "    return init_tensor\n",
    "\n",
    "def inference(batch_input):\n",
    "    # batch_input : [batch_size, input_dim]  # ex) mnist case : 784\n",
    "    \n",
    "    # do inference & and return logits\n",
    "    # return [batch_size, 10]   # 10 = [0,1,2,....,9]\n",
    "\n",
    "    # 3 layer \n",
    "    # 784 --> 128 --> 32\n",
    "    input_dim = 784\n",
    "    h1_dim = 144\n",
    "    h2_dim = 36\n",
    "    output_dim = 10\n",
    "    with tf.variable_scope(\"hidden_1\"):\n",
    "        W = tf.Variable( variable_init_2D(input_dim, h1_dim), name='weights')\n",
    "        b = tf.Variable( tf.zeros([h1_dim]), name='biases')\n",
    "        out_h1 = tf.nn.relu( tf.matmul(batch_input, W) + b )\n",
    "    \n",
    "    with tf.variable_scope(\"hidden_2\"):\n",
    "        W = tf.Variable( variable_init_2D(h1_dim, h2_dim), name='weights')\n",
    "        b = tf.Variable( tf.zeros([h2_dim]), name='biases')\n",
    "        out_h2 = tf.nn.relu( tf.matmul(out_h1, W) + b )\n",
    "    \n",
    "    with tf.variable_scope(\"hidden_3\"):\n",
    "        W = tf.Variable( variable_init_2D(h2_dim, output_dim), name='weights')\n",
    "        b = tf.Variable( tf.zeros([output_dim]), name='biases')\n",
    "        \n",
    "        # no activation at final layer\n",
    "        out_h3 = tf.matmul(out_h2, W) + b\n",
    "        \n",
    "    return out_h1, out_h2, out_h3\n",
    "\n",
    "# check\n",
    "b_image, _ = batch_reader(0)\n",
    "inference(b_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def loss(batch_logits, batch_ref):\n",
    "    # batch_logits : inference result [batch_size, output_dim] ex) mnist case : output_dim =10\n",
    "    # batch_ref    : reference        [batch_size]\n",
    "    \n",
    "    \n",
    "    # calculate loss\n",
    "    # from : https://www.tensorflow.org/versions/r0.11/api_docs/python/nn.html#sparse_softmax_cross_entropy_with_logits\n",
    "    \n",
    "    _batch_loss = tf.nn.sparse_softmax_cross_entropy_with_logits(batch_logits, batch_ref)\n",
    "    \n",
    "    # return : scala_value\n",
    "    # loss collapsed! (batch-wise)\n",
    "    _loss = tf.reduce_mean(_batch_loss)\n",
    "    return _loss\n",
    "   \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameter Update Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def updator(loss_op):\n",
    "    # do update for minimizing loss from loss_op\n",
    "    #\n",
    "    \n",
    "    opt = tf.train.GradientDescentOptimizer\n",
    "    #opt = tf.train.AdamOptimizer\n",
    "    \n",
    "    optimizer = opt(learning_rate=0.1)\n",
    "    update_op = optimizer.minimize(loss_op)\n",
    "    \n",
    "    return update_op\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graph Connection && Placeholder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"pl_image:0\", shape=(100, 784), dtype=float32)\n",
      "Tensor(\"pl_label:0\", shape=(100,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "# placeholder for batch input & output\n",
    "pl_batch_input = tf.placeholder(tf.float32, shape=(batch_size, 784), name='pl_image')\n",
    "pl_batch_ref   = tf.placeholder(tf.int32,   shape=(batch_size),      name='pl_label')\n",
    "\n",
    "# check\n",
    "print pl_batch_input\n",
    "print pl_batch_ref"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"hidden_3_1/add:0\", shape=(100, 10), dtype=float32)\n",
      "Tensor(\"Mean:0\", shape=(), dtype=float32)\n",
      "name: \"GradientDescent\"\n",
      "op: \"NoOp\"\n",
      "input: \"^GradientDescent/update_hidden_1_1/weights/ApplyGradientDescent\"\n",
      "input: \"^GradientDescent/update_hidden_1_1/biases/ApplyGradientDescent\"\n",
      "input: \"^GradientDescent/update_hidden_2_1/weights/ApplyGradientDescent\"\n",
      "input: \"^GradientDescent/update_hidden_2_1/biases/ApplyGradientDescent\"\n",
      "input: \"^GradientDescent/update_hidden_3_1/weights/ApplyGradientDescent\"\n",
      "input: \"^GradientDescent/update_hidden_3_1/biases/ApplyGradientDescent\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# flow : inference --> loss --> updator --> training loop\n",
    "_, _, batch_logits = inference(pl_batch_input)    # batch_input <-- will be placed\n",
    "loss_op = loss(batch_logits, pl_batch_ref)        # batch_ref <--- will be placed \n",
    "updator_op = updator(loss_op)\n",
    "\n",
    "# check\n",
    "print batch_logits\n",
    "print loss_op\n",
    "print updator_op"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initalize Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "# init all variable before training loop\n",
    "init_op = tf.initialize_all_variables()\n",
    "sess.run(init_op)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_size :  100\n",
      "\t >> Epoch Step 1 loss 1.27505600452\n",
      "\t >> Epoch Step 2 loss 0.448837518692\n",
      "\t >> Epoch Step 3 loss 0.340164273977\n",
      "\t >> Epoch Step 4 loss 0.287963986397\n",
      "\t >> Epoch Step 5 loss 0.251861542463\n",
      "\t >> Epoch Step 6 loss 0.223167270422\n",
      "\t >> Epoch Step 7 loss 0.199447855353\n",
      "\t >> Epoch Step 8 loss 0.178755223751\n",
      "\t >> Epoch Step 9 loss 0.160903334618\n",
      "\t >> Epoch Step 10 loss 0.144714295864\n",
      "\t >> Epoch Step 11 loss 0.130465477705\n",
      "\t >> Epoch Step 12 loss 0.117829665542\n",
      "\t >> Epoch Step 13 loss 0.106353327632\n",
      "\t >> Epoch Step 14 loss 0.0963449850678\n",
      "\t >> Epoch Step 15 loss 0.0873490124941\n",
      "\t >> Epoch Step 16 loss 0.0793978795409\n",
      "\t >> Epoch Step 17 loss 0.0729095339775\n",
      "\t >> Epoch Step 18 loss 0.0684738606215\n",
      "\t >> Epoch Step 19 loss 0.0617712587118\n",
      "\t >> Epoch Step 20 loss 0.05501909554\n",
      "\t >> Epoch Step 21 loss 0.0498677715659\n",
      "\t >> Epoch Step 22 loss 0.0448025763035\n",
      "\t >> Epoch Step 23 loss 0.0398697406054\n",
      "\t >> Epoch Step 24 loss 0.035295329988\n",
      "\t >> Epoch Step 25 loss 0.0314673483372\n",
      "\t >> Epoch Step 26 loss 0.0281971041113\n",
      "\t >> Epoch Step 27 loss 0.0253672711551\n",
      "\t >> Epoch Step 28 loss 0.0229546278715\n",
      "\t >> Epoch Step 29 loss 0.0208275374025\n",
      "\t >> Epoch Step 30 loss 0.0189588218927\n",
      "\t >> Epoch Step 31 loss 0.0172719620168\n",
      "\t >> Epoch Step 32 loss 0.0158572010696\n",
      "\t >> Epoch Step 33 loss 0.0145209301263\n",
      "\t >> Epoch Step 34 loss 0.0133843580261\n",
      "\t >> Epoch Step 35 loss 0.0123608624563\n",
      "\t >> Epoch Step 36 loss 0.011421023868\n",
      "\t >> Epoch Step 37 loss 0.0106088332832\n",
      "\t >> Epoch Step 38 loss 0.00987046491355\n",
      "\t >> Epoch Step 39 loss 0.00921084731817\n",
      "\t >> Epoch Step 40 loss 0.00861916784197\n",
      "\t >> Epoch Step 41 loss 0.00808908604085\n",
      "\t >> Epoch Step 42 loss 0.00761782750487\n",
      "\t >> Epoch Step 43 loss 0.00717377802357\n",
      "\t >> Epoch Step 44 loss 0.00677801668644\n",
      "\t >> Epoch Step 45 loss 0.00642397534102\n",
      "\t >> Epoch Step 46 loss 0.00609370600432\n",
      "\t >> Epoch Step 47 loss 0.00578853068873\n",
      "\t >> Epoch Step 48 loss 0.00550893507898\n",
      "\t >> Epoch Step 49 loss 0.00525061972439\n",
      "\t >> Epoch Step 50 loss 0.00501503655687\n",
      "\t >> Epoch Step 51 loss 0.00479562114924\n",
      "\t >> Epoch Step 52 loss 0.0045904321596\n",
      "\t >> Epoch Step 53 loss 0.0044004144147\n",
      "\t >> Epoch Step 54 loss 0.00422643683851\n",
      "\t >> Epoch Step 55 loss 0.00405816407874\n",
      "\t >> Epoch Step 56 loss 0.00390789471567\n",
      "\t >> Epoch Step 57 loss 0.00375948240981\n",
      "\t >> Epoch Step 58 loss 0.00362507067621\n",
      "\t >> Epoch Step 59 loss 0.00350314029492\n",
      "\t >> Epoch Step 60 loss 0.00337862037122\n",
      "\t >> Epoch Step 61 loss 0.00326759903692\n",
      "\t >> Epoch Step 62 loss 0.00315971043892\n",
      "\t >> Epoch Step 63 loss 0.00305986916646\n",
      "\t >> Epoch Step 64 loss 0.00296536437236\n",
      "\t >> Epoch Step 65 loss 0.00287620909512\n",
      "\t >> Epoch Step 66 loss 0.00278972182423\n",
      "\t >> Epoch Step 67 loss 0.00270858383738\n",
      "\t >> Epoch Step 68 loss 0.00263281678781\n",
      "\t >> Epoch Step 69 loss 0.00255753006786\n",
      "\t >> Epoch Step 70 loss 0.00248904130422\n",
      "\t >> Epoch Step 71 loss 0.00242191017605\n",
      "\t >> Epoch Step 72 loss 0.00235955859534\n",
      "\t >> Epoch Step 73 loss 0.00229853927158\n",
      "\t >> Epoch Step 74 loss 0.00224111229181\n",
      "\t >> Epoch Step 75 loss 0.00218349834904\n",
      "\t >> Epoch Step 76 loss 0.00213136710227\n",
      "\t >> Epoch Step 77 loss 0.00208049756475\n",
      "\t >> Epoch Step 78 loss 0.00203114934266\n",
      "\t >> Epoch Step 79 loss 0.00198413920589\n",
      "\t >> Epoch Step 80 loss 0.00193882081658\n",
      "\t >> Epoch Step 81 loss 0.00189618114382\n",
      "\t >> Epoch Step 82 loss 0.00185363844503\n",
      "\t >> Epoch Step 83 loss 0.00181432475802\n",
      "\t >> Epoch Step 84 loss 0.00177561899181\n",
      "\t >> Epoch Step 85 loss 0.00173900742084\n",
      "\t >> Epoch Step 86 loss 0.00170229270589\n",
      "\t >> Epoch Step 87 loss 0.00166868825909\n",
      "\t >> Epoch Step 88 loss 0.00163450581022\n",
      "\t >> Epoch Step 89 loss 0.00160304759629\n",
      "\t >> Epoch Step 90 loss 0.00157198368106\n",
      "\t >> Epoch Step 91 loss 0.00154166738503\n",
      "\t >> Epoch Step 92 loss 0.00151266052853\n",
      "\t >> Epoch Step 93 loss 0.00148435751908\n",
      "\t >> Epoch Step 94 loss 0.00145717244595\n",
      "\t >> Epoch Step 95 loss 0.00143094768282\n",
      "\t >> Epoch Step 96 loss 0.00140502420254\n",
      "\t >> Epoch Step 97 loss 0.00138139771298\n",
      "\t >> Epoch Step 98 loss 0.00135639880318\n",
      "\t >> Epoch Step 99 loss 0.00133341376204\n",
      "\t >> Epoch Step 100 loss 0.0013105252292\n",
      "\t >> Epoch Step 101 loss 0.00128899305128\n"
     ]
    }
   ],
   "source": [
    "epoch = 0\n",
    "step = 0 \n",
    "start_index = 0\n",
    "print \"batch_size : \", batch_size\n",
    "epoch_losses = []\n",
    "while True:\n",
    "    if epoch > 100: break\n",
    "    step += 1\n",
    "    \n",
    "    ## --- every step ----\n",
    "    ## do params. update batchwise\n",
    "    batch_input, batch_refs = batch_reader(start_index)\n",
    "    if len(batch_input) < 1 : \n",
    "        # epoch is finished\n",
    "        epoch += 1\n",
    "        start_index = 0\n",
    "        print \"\\t >> Epoch Step {} loss {}\".format(epoch, np.mean(epoch_losses))\n",
    "        epoch_losses = []\n",
    "        continue \n",
    "    \n",
    "    feed_dict = {\n",
    "                    pl_batch_input : batch_input,\n",
    "                    pl_batch_ref   : batch_refs,\n",
    "                }\n",
    "    loss_value, _ = sess.run( [loss_op, updator_op], \n",
    "                             feed_dict=feed_dict\n",
    "                            )\n",
    "    \"\"\"if step % 10 == 0: \n",
    "        print \"Epoch : {} Step : {} Loss : {}\".format(epoch, step, loss_value)\n",
    "    \"\"\"\n",
    "    epoch_losses.append( loss_value ) \n",
    "    \n",
    "        \n",
    "    start_index += batch_size "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
